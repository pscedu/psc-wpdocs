Research Engineer in the [HPC AI and Big Data](http://cmu.edu/psc/aibd) group; supporting the User Community for PSC's [Bridges-2](https://www.psc.edu/bridges-2), and [Neocortex](https://www.cmu.edu/psc/aibd/neocortex/); while also leading the development of [COSMO](https://www.cmu.edu/cosmology/news/articles/2020-05-15_seed-grant-recipients.html), a REST API for exploring the [BlueTides simulation data](http://bluetides-project.org/) from the [McWilliams Center for Cosmology](https://www.cmu.edu/cosmology/).

Julian joined the Pittsburgh Supercomputing Center in 2019 after working as Senior Technical Support and Customer Operations Engineer at [Hortonworks and Cloudera Inc.](https://www.cloudera.com/) Prior to that, He contributed to the University of Delaware [Global Computing Lab](https://globalcomputing.group/), University of Los Andes [COMIT](https://sistemas.uniandes.edu.co/en/research/groups/comit-en) Research Group, Technological University of Pereira [Sirius HPC](https://sirius.utp.edu.co/) Research Group; and worked as a Software Developer for top-performing companies in Latin America and the Caribbean region ([VeriTran](https://www.veritran.com/), [BeMovil](https://www.bemovil.net/)) after earning his Master's degree in Systems and Computer Engineering from Universidad de los Andes (University of the Andes) in 2012.

**Interests:** Virtualization, Web Development, Entrepreneurship, User Experience Optimization.

## News

### 2022
* Primary Author for the [Practice and Experience in Advanced Research Computing 2022 (PEARC22)](https://dl.acm.org/doi/proceedings/10.1145/3491418) Conference paper [COSMO: a Research Data Service Platform and Experiences from the BlueTides Project](https://dl.acm.org/doi/10.1145/3491418.3535166). Winner of the best short-paper award for the Applications and Software track.
* Won the [2022 Outstanding Achievement Award for the Pittsburgh Supercomputing Center](https://www.cmu.edu/mcs/news-events/2022/0610_mcs-staff-awards.html) from the Mellon College of Science, for significant contributions to the Neocortex project, which is funded by the NSF, having helped deploy the innovative supercomputer and keep it running despite notable technical challenges.
* Deployed a multi-GPU test system for the Open-Compass project with AMD Instinct M100 GPUs.
* Deployed a Graphcore testbed using a [BOW-2000 IPU Machine](https://www.graphcore.ai/products/bow-2000).
* Supported the [Neocortex migration from Cerebras CS-1 to CS-2 machines](https://www.cmu.edu/psc/aibd/neocortex/2022-03-neocortex-cs2-overview.html).
* Participated as presenter in the Annual Neocortex NSF Acquisition Review Panel: Software Stack, Operations, Security, Virtual Neocortex Display.
* As a member of the Bridges-2 Continuous Improvement Committee (CIC), proposed ideas and helped implement improvements for the [Bridges-2 OnDemand platform](https://ondemand.bridges2.psc.edu/). 
* Joined the Bridges-2 Software Task Force, for working as a team to generate: Bridges-2 Services Definitions, Requirements, and Deployment Task Force Standard Operating Procedures.

### 2021
* Aided the [Bridges](https://www.psc.edu/resources/bridges/) to [Bridges-2](https://www.psc.edu/resources/bridges-2/) migration process by thoroughly documenting and running performance evaluation benchmarks in preparation for acceptance testing, needed for the Bridges-2 supercomputer to be successfully accepted and for performance reviews, and questions from the evaluators, to advance without problems.
* Implemented the first version of the Data Sharing Portal for the McWilliams Center for Cosmology. This allowed a limited set of files of the [BlueTides Simulation](https://bluetides.psc.edu/) to be made publicly available via a web interface, something that was being done to a limited degree in a decentralized way with a web server.
* Migrated and revamped the [AIBD website](https://www.cmu.edu/psc/aibd/) to the CMU Content Management System, including a [Neocortex System](https://www.cmu.edu/psc/aibd/neocortex/) section. This helped centralize the content under one manageable platform that is kept up to date by the CMU Technology team, in which an ongoing website design effort had been applied on the old website but needed to be replaced because of the effort required to develop and adapt requirements.
* Implemented the [Neocortex Portal](https://portal.neocortex.psc.edu/) webpage for the Neocortex users to have access to news and documentation, as a way to have a fluid and structured way to share information with them while keeping track of their project statuses and information. This involved the inclusion of the [MkDocs](https://www.mkdocs.org/) documentation system to the Portal, as a way to enable the content to be edited by the multiple _Neocortex_ Team members while having it under version control.
* Implemented the [Neocortex Documentation](https://portal.neocortex.psc.edu/docs/) page using [MkDocs](https://www.mkdocs.org/), as an independent component of the Neocortex Portal.
* Coordinated efforts for deploying and configuring the [Neocortex system](https://www.cmu.edu/psc/aibd/neocortex/), constantly communicating with multiple teams over three companies (PSC, Cerebras Inc, HPE) for successfully deploying on site the technical equipment required for the specialized hardware to start operating, [a $5M project sponsored by the NSF](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2005597).
* Attended the "Neocortex Admin Training" by Cerebras, covering contents for System Administration and Operation on February 10, 2021.
* Generated [software modules](https://www.psc.edu/resources/software/ai/) for the most popular AI frameworks and libraries to be used on the Bridges-2 cluster.
* Worked with the Bridges-2 Acceptance Testing team for making sure the cluster was able to perform as expected when using the MXnet and TensorRT frameworks. 
* Led the Neocortex Superdome Flex system configuration, a multi-chassis (8 chassis total) configured as logical partitions, each partition with 16 CPUs, 100TB of multi-drive NVMe flash RAID storage, 12TB of RAM memory, 100GbE network interfaces, and 8 InfiniBand network interfaces which are all expected to work to the top of their performance (aggregated speeds) when running jobs on the Neocortex system.
* Started working as member of the Bridges-2 Continuous Improvement Committee (CIC) from improving the experience researchers have when using the Bridges-2 cluster.
* Participated on the ICDAR 2021 Conference paper [MiikeMineStamps: A Long-Tailed Dataset of Japanese Stamps via Active Learning](https://link.springer.com/chapter/10.1007/978-3-030-86334-0_1), on the Document Analysis and Recognition category (co-author).
* Participated on the [Practice and Experience in Advanced Research Computing  2021 (PEARC21)](https://dl.acm.org/doi/proceedings/10.1145/3437359) Conference paper "[System Integration of Neocortex, a Unique, Scalable AI Platform](https://dl.acm.org/doi/10.1145/3437359.3465604)" (co-author).
* Part of the team that won the [2021 Mellon College of Science Outstanding Team Recognition Award for the Pittsburgh Supercomputing department](https://www.cmu.edu/mcs/news-events/2021/0617_staff-awards-2021.html) from the Mellon College of Science, for deploying two world-class supercomputing resources, BRIDGES-2 and Neocortex, in the midst of the ongoing pandemic. Despite several challenges, delays and hardships, the BRIDGES-2/Neocortex team persevered and through extreme dedication and heroic efforts were able to field these two machines for the scientific research community.
* Participated as presenter in the Annual Neocortex NSF Operations Review Panel: Operations Performance for Neocortex Testbed Operations Year 1.

### 2020
* Implemented a navigation tool for the image labeler software “[Label Me](https://github.com/CSAILVision/LabelMeAnnotationTool)”, a critical piece of software that enabled research for an [XSEDE ECSS project](https://www.xsede.org/for-users/ecss/ecss-projects) that has already generated a paper for the International Conference on Document Analysis and Recognition 2021 ([ICDAR 2021](https://icdar2021.org/)).
* Helped the [HuBMAP Consortium](https://hubmapconsortium.org/) launch containers on demand via SLURM on the Bridges supercomputer, enabling the project to pave the way for running research workflows on multiple clusters.
* Performed a refresh of the first CALIMA software implementation for mining data from the [Bridges supercomputer](https://www.psc.edu/resources/bridges-2/) SLURM history and started a whitepaper on this subject. The goal is to predict when it is that jobs will start their execution, and what modifications could be made for getting jobs to start running with lower queuing times.
* Supported PSC's critical role in the [COVID-19 High-Performance Computing Consortium](https://covid19-hpc-consortium.org/) by helping multiple groups with their COVID-19 research efforts by going above and beyond providing technical support and suggesting optimizations for their job executions on a daily basis, continuously spending late night hours with the different teams for solving any issues encountered on those world-wide-interest research projects, critical for the wellbeing of everyone. 
* Applied to the McWilliams Center/PSC Seed Funding 2020 Program with [COSMO, a REST API for Cosmology Data](https://bluetides.psc.edu/).
* Earned the [McWilliams/PSC Seed Grant 2020](https://www.cmu.edu/cosmology/news/articles/2020-05-15_seed-grant-recipients.html), for which ~$20K in funds were used to hire and lead two graduate interns on implementing a [platform](https://bluetides.psc.edu/) for sharing petabyte-scale simulations and datasets via multiple endpoints, such as having a web portal, a RESTful API, and a Globus endpoint for users to explore the [BlueTides Simulation](https://bluetides.psc.edu/) data on the way that best suit their needs.
* [Won the Editor's Choice Award from HPCWire](https://www.youtube.com/watch?v=Gy-NHpYm-Pk), a leading publication in the high-performance computing field, for "[Best Use of High-Performance Data Analytics & Artificial Intelligence](https://www.hpcwire.com/off-the-wire/hpcwire-reveals-winners-of-the-2020-readers-and-editors-choice-awards-during-sc20s-virtual-conference/)" during the virtual 2020 International Conference for High-Performance Computing, Networking, Storage and Analysis (SC20), as part of the team lead by Dr. Olexandr Isayev from CMU.
* Nominated for an Andy Award in the [Teamwork and Collaboration](https://www.cmu.edu/andyawards/nominees/teamwork-and-collaboration.html) category as part of the PSC COVID-19 Rapid Response Team.
* Attended the tutorials section of the [HotChips Conference 2020](https://hotchips.org/archives/hc32/#tutorials-sunday-august-16-2020) for general information on how to scale out Machine Learning using NVIDIA, Google, and Cerebras Inc systems.
* Attended NVIDIA's GPU Tech Conference, GTC 2020, for the latest developments on NVIDIA technology.
* Attended the ICML20 conference virtually (July 2020)
* Attended the [XSEDE HPC Workshop: MPI](https://portal.xsede.org/online-training), on September 1-2, 2020, a basic MPI-focused training for developing code for HPC environments.
* Attended the [MIT Professional Education - Short Programs: Designing Efficient Deep Learning Systems](https://professional.mit.edu/course-catalog/designing-efficient-deep-learning-systems). A two-day course on how Deep Learning works and what systems are considered good for running DL workflows.
* For outstanding contributions to the center and more specifically to the AI and Big Data group’s mission, was awarded the [Staff Recognition Rookie Award from the Mellon College of Science](https://www.cmu.edu/mcs/news-events/2020/0608_staff-awards-2020.html), given to Staff members that have contributed greatly to the Pittsburgh Supercomputing Center.
* Part of the team that won the [Staff Recognition PSC- COVID-19 Outstanding Team Achievement Award](https://www.cmu.edu/mcs/news-events/2020/0608_staff-awards-2020.html) from the Mellon College of Science, for all the effort and results while collaborating with research groups on crucial COVID-19 projects.
* Assisted with a section of the "[Hands-on Virtual Training - Getting Ready to Use the Neocortex System](https://www.cmu.edu/psc/aibd/neocortex/technical-tutorial.html)" training on December 8 and 9, 2020. An overview of how to run compilation and training workflows using the _Neocortex_ system with the Cerebras CS-1 boxes.